---------------------------------------------------------------------------------------------------------------------
Starting Hadoop Services
---------------------------------------------------------------------------------------------------------------------
sam@ubuntu:~$ hadoop-2.6.0/sbin/start-all.sh
This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
Starting namenodes on [localhost]
localhost: starting namenode, logging to /home/sam/hadoop-2.6.0/logs/hadoop-sam-namenode-ubuntu.out
localhost: starting datanode, logging to /home/sam/hadoop-2.6.0/logs/hadoop-sam-datanode-ubuntu.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /home/sam/hadoop-2.6.0/logs/hadoop-sam-secondarynamenode-ubuntu.out
starting yarn daemons
starting resourcemanager, logging to /home/sam/hadoop-2.6.0/logs/yarn-sam-resourcemanager-ubuntu.out
localhost: starting nodemanager, logging to /home/sam/hadoop-2.6.0/logs/yarn-sam-nodemanager-ubuntu.out
sam@ubuntu:~$ jps
3305 DataNode
3786 NodeManager
3515 SecondaryNameNode
3662 ResourceManager
3182 NameNode
4079 Jps

---------------------------------------------------------------------------------------------------------------------
wordcount
---------------------------------------------------------------------------------------------------------------------
sam@ubuntu:~$ hadoop fs -mkdir /data
sam@ubuntu:~$ hadoop fs -ls /
Found 1 items
drwxr-xr-x   - sam supergroup          0 2015-07-10 23:52 /data
sam@ubuntu:~$ hadoop fs -ls /data
sam@ubuntu:~$ hadoop fs -put /home/sam/data/ipl.txt /data
sam@ubuntu:~$ hadoop fs -ls /data
Found 1 items
-rw-r--r--   1 sam supergroup        524 2015-07-10 23:53 /data/ipl.txt

sam@ubuntu:~$ hadoop jar /home/sam/Desktop/wordcount.jar wordcount.ClsDriver /data/ipl.txt /wordcountT
15/07/11 00:37:07 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/07/11 00:37:09 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/07/11 00:37:09 INFO input.FileInputFormat: Total input paths to process : 1
15/07/11 00:37:10 INFO mapreduce.JobSubmitter: number of splits:1
15/07/11 00:37:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1436597144045_0001
15/07/11 00:37:11 INFO impl.YarnClientImpl: Submitted application application_1436597144045_0001
15/07/11 00:37:12 INFO mapreduce.Job: The url to track the job: http://ubuntu:8088/proxy/application_1436597144045_0001/
15/07/11 00:37:12 INFO mapreduce.Job: Running job: job_1436597144045_0001
15/07/11 00:37:26 INFO mapreduce.Job: Job job_1436597144045_0001 running in uber mode : false
15/07/11 00:37:26 INFO mapreduce.Job:  map 0% reduce 0%
15/07/11 00:37:36 INFO mapreduce.Job:  map 100% reduce 0%
15/07/11 00:37:43 INFO mapreduce.Job:  map 100% reduce 100%
15/07/11 00:37:43 INFO mapreduce.Job: Job job_1436597144045_0001 completed successfully
15/07/11 00:37:43 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=1375
		FILE: Number of bytes written=214055
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=623
		HDFS: Number of bytes written=47
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=6933
		Total time spent by all reduces in occupied slots (ms)=3709
		Total time spent by all map tasks (ms)=6933
		Total time spent by all reduce tasks (ms)=3709
		Total vcore-seconds taken by all map tasks=6933
		Total vcore-seconds taken by all reduce tasks=3709
		Total megabyte-seconds taken by all map tasks=7099392
		Total megabyte-seconds taken by all reduce tasks=3798016
	Map-Reduce Framework
		Map input records=21
		Map output records=141
		Map output bytes=1087
		Map output materialized bytes=1375
		Input split bytes=99
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=1375
		Reduce input records=141
		Reduce output records=7
		Spilled Records=282
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=567
		CPU time spent (ms)=3320
		Physical memory (bytes) snapshot=423997440
		Virtual memory (bytes) snapshot=3817189376
		Total committed heap usage (bytes)=296222720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=524
	File Output Format Counters 
		Bytes Written=47
sam@ubuntu:~$ hadoop fs -cat /wordcountT/part-r-00000
DD	19
KIXP	21
KKR	20
MI	20
RCB	19
RR	23
SRH	19

---------------------------------------------------------------------------------------------------------------------
nas
---------------------------------------------------------------------------------------------------------------------
sam@ubuntu:~$ hadoop fs -put /home/sam/data/nameAgeScore.txt /data
sam@ubuntu:~$ hadoop jar /home/sam/Desktop/nas.jar nas.ClsDriver /data/nameAgeScore.txt /nas
15/07/11 00:59:26 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/07/11 00:59:27 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/07/11 00:59:27 INFO input.FileInputFormat: Total input paths to process : 1
15/07/11 00:59:27 INFO mapreduce.JobSubmitter: number of splits:1
15/07/11 00:59:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1436597144045_0002
15/07/11 00:59:28 INFO impl.YarnClientImpl: Submitted application application_1436597144045_0002
15/07/11 00:59:28 INFO mapreduce.Job: The url to track the job: http://ubuntu:8088/proxy/application_1436597144045_0002/
15/07/11 00:59:28 INFO mapreduce.Job: Running job: job_1436597144045_0002
15/07/11 00:59:34 INFO mapreduce.Job: Job job_1436597144045_0002 running in uber mode : false
15/07/11 00:59:34 INFO mapreduce.Job:  map 0% reduce 0%
15/07/11 00:59:41 INFO mapreduce.Job:  map 100% reduce 0%
15/07/11 00:59:47 INFO mapreduce.Job:  map 100% reduce 100%
15/07/11 00:59:47 INFO mapreduce.Job: Job job_1436597144045_0002 completed successfully
15/07/11 00:59:47 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=150
		FILE: Number of bytes written=211949
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=352
		HDFS: Number of bytes written=10
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=5494
		Total time spent by all reduces in occupied slots (ms)=2993
		Total time spent by all map tasks (ms)=5494
		Total time spent by all reduce tasks (ms)=2993
		Total vcore-seconds taken by all map tasks=5494
		Total vcore-seconds taken by all reduce tasks=2993
		Total megabyte-seconds taken by all map tasks=5625856
		Total megabyte-seconds taken by all reduce tasks=3064832
	Map-Reduce Framework
		Map input records=18
		Map output records=18
		Map output bytes=108
		Map output materialized bytes=150
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=150
		Reduce input records=18
		Reduce output records=2
		Spilled Records=36
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=211
		CPU time spent (ms)=1660
		Physical memory (bytes) snapshot=429453312
		Virtual memory (bytes) snapshot=3817472000
		Total committed heap usage (bytes)=304611328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=244
	File Output Format Counters 
		Bytes Written=10
sam@ubuntu:~$ hadoop fs -cat /nas/part-r-00000
f	92
m	82
sam@ubuntu:~$ hadoop fs -ls /nas
Found 2 items
-rw-r--r--   1 sam supergroup          0 2015-07-11 00:59 /nas/_SUCCESS
-rw-r--r--   1 sam supergroup         10 2015-07-11 00:59 /nas/part-r-00000
sam@ubuntu:~$ hadoop fs -cat /nas/*
f	92
m	82

---------------------------------------------------------------------------------------------------------------------
wordcountCombiner
---------------------------------------------------------------------------------------------------------------------
sam@ubuntu:~$ hadoop fs -put /home/sam/data/ipl1.txt /data
sam@ubuntu:~$ hadoop jar /home/sam/Desktop/wordcountCombiner.jar wordcountCombiner.ClsDriver /data/ipl1.txt /wordcountCombiner
15/07/11 01:44:29 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/07/11 01:44:30 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/07/11 01:44:31 INFO input.FileInputFormat: Total input paths to process : 1
15/07/11 01:44:31 INFO mapreduce.JobSubmitter: number of splits:1
15/07/11 01:44:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1436597144045_0005
15/07/11 01:44:32 INFO impl.YarnClientImpl: Submitted application application_1436597144045_0005
15/07/11 01:44:32 INFO mapreduce.Job: The url to track the job: http://ubuntu:8088/proxy/application_1436597144045_0005/
15/07/11 01:44:32 INFO mapreduce.Job: Running job: job_1436597144045_0005
15/07/11 01:44:43 INFO mapreduce.Job: Job job_1436597144045_0005 running in uber mode : false
15/07/11 01:44:43 INFO mapreduce.Job:  map 0% reduce 0%
15/07/11 01:44:59 INFO mapreduce.Job:  map 59% reduce 0%
15/07/11 01:45:01 INFO mapreduce.Job:  map 100% reduce 0%
15/07/11 01:45:12 INFO mapreduce.Job:  map 100% reduce 100%
15/07/11 01:45:12 INFO mapreduce.Job: Job job_1436597144045_0005 completed successfully
15/07/11 01:45:13 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=318
		FILE: Number of bytes written=212159
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=16869963
		HDFS: Number of bytes written=85
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=15541
		Total time spent by all reduces in occupied slots (ms)=7871
		Total time spent by all map tasks (ms)=15541
		Total time spent by all reduce tasks (ms)=7871
		Total vcore-seconds taken by all map tasks=15541
		Total vcore-seconds taken by all reduce tasks=7871
		Total megabyte-seconds taken by all map tasks=15913984
		Total megabyte-seconds taken by all reduce tasks=8059904
	Map-Reduce Framework
		Map input records=645120
		Map output records=4548087
		Map output bytes=35062208
		Map output materialized bytes=156
		Input split bytes=100
		Combine input records=4548087
		Combine output records=15
		Reduce input groups=8
		Reduce shuffle bytes=156
		Reduce input records=15
		Reduce output records=8
		Spilled Records=45
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=433
		CPU time spent (ms)=7690
		Physical memory (bytes) snapshot=412934144
		Virtual memory (bytes) snapshot=3829366784
		Total committed heap usage (bytes)=293076992
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16869863
	File Output Format Counters 
		Bytes Written=85
sam@ubuntu:~$ hadoop fs -cat /wordcountCombiner/*
DD	612863
KIXP	677373
KKR	645119
MI	645119
RCB	612861
RCBKIXP	2
RR	741887
SRH	612863

---------------------------------------------------------------------------------------------------------------------
nasCP
---------------------------------------------------------------------------------------------------------------------
sam@ubuntu:~$ hadoop fs -put /home/sam/data/nameAgeScore1.txt /data
sam@ubuntu:~$ hadoop jar /home/sam/Desktop/MapReduceJARs/nasCP.jar nasCP.ClsDriver /data/nameAgeScore1.txt /nasCP2
15/07/11 02:21:48 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/07/11 02:21:49 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/07/11 02:21:49 INFO input.FileInputFormat: Total input paths to process : 1
15/07/11 02:21:49 INFO mapreduce.JobSubmitter: number of splits:1
15/07/11 02:21:49 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1436597144045_0007
15/07/11 02:21:50 INFO impl.YarnClientImpl: Submitted application application_1436597144045_0007
15/07/11 02:21:50 INFO mapreduce.Job: The url to track the job: http://ubuntu:8088/proxy/application_1436597144045_0007/
15/07/11 02:21:50 INFO mapreduce.Job: Running job: job_1436597144045_0007
15/07/11 02:21:56 INFO mapreduce.Job: Job job_1436597144045_0007 running in uber mode : false
15/07/11 02:21:56 INFO mapreduce.Job:  map 0% reduce 0%
15/07/11 02:22:01 INFO mapreduce.Job:  map 100% reduce 0%
15/07/11 02:22:09 INFO mapreduce.Job:  map 100% reduce 33%
15/07/11 02:22:11 INFO mapreduce.Job:  map 100% reduce 67%
15/07/11 02:22:12 INFO mapreduce.Job:  map 100% reduce 100%
15/07/11 02:22:12 INFO mapreduce.Job: Job job_1436597144045_0007 completed successfully
15/07/11 02:22:13 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=334
		FILE: Number of bytes written=424511
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=353
		HDFS: Number of bytes written=79
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2642
		Total time spent by all reduces in occupied slots (ms)=19650
		Total time spent by all map tasks (ms)=2642
		Total time spent by all reduce tasks (ms)=19650
		Total vcore-seconds taken by all map tasks=2642
		Total vcore-seconds taken by all reduce tasks=19650
		Total megabyte-seconds taken by all map tasks=2705408
		Total megabyte-seconds taken by all reduce tasks=20121600
	Map-Reduce Framework
		Map input records=18
		Map output records=18
		Map output bytes=280
		Map output materialized bytes=334
		Input split bytes=109
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=334
		Reduce input records=18
		Reduce output records=6
		Spilled Records=36
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=411
		CPU time spent (ms)=3600
		Physical memory (bytes) snapshot=747270144
		Virtual memory (bytes) snapshot=7643000832
		Total committed heap usage (bytes)=490733568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=244
	File Output Format Counters 
		Bytes Written=79
sam@ubuntu:~$ hadoop fs -ls /nasCP2/*
-rw-r--r--   1 sam supergroup          0 2015-07-11 02:22 /nasCP2/_SUCCESS
-rw-r--r--   1 sam supergroup         27 2015-07-11 02:22 /nasCP2/part-r-00000
-rw-r--r--   1 sam supergroup         27 2015-07-11 02:22 /nasCP2/part-r-00001
-rw-r--r--   1 sam supergroup         25 2015-07-11 02:22 /nasCP2/part-r-00002
sam@ubuntu:~$ hadoop fs -cat /nasCP2/part-r-00000
f	erik,22,92
m	alice,24,57
sam@ubuntu:~$ hadoop fs -cat /nasCP2/part-r-00001
f	john,42,89
m	jason,37,57
sam@ubuntu:~$ hadoop fs -cat /nasCP2/part-r-00002
f	alia,30,87
m	ali,31,82

---------------------------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------------------------

